---
title: "05_sr_matchups"
output: html_document
editor_options: 
  chunk_output_type: console
---
#Pull surface reflectance values associated with in situ samples.

This script takes the shouldered, filtered in situ water quality dataset pulled from the Water Quality Portal/LAGOS and extracts associated Landsat surface reflectance values from Google Earth Engine.  The pulled reflectance values are the median pixel value of pixels with 80% water occurence (according to Pekel) within 120m of the provided lat/long of the in situ sample identified in the water quality dataset.  The standard deviation of the water pixel reflectance is included to enable quality control filtering.

```{r setup, include=FALSE}
#install_github("JesJehle/earthEngineGrabR")

library(devtools)
library(earthEngineGrabR)
library(tidyverse)
library(feather)
library(knitr)
library(purrr)
library(reticulate)
library(googledrive)

## Run these once
#ee_grab_install(clean_credentials = T, clean_environment = T)
#use_condaenv("earthengineGrabR")
#conda_install('feather-format', envname = 'earthEngineGrabR')

```

#Retrieve existing data to avoid duplicating reflectance pulls

Create a list of existing reflectance csv's to filter whats been pulled down from GEE already.

```{r Get Existing}
#Retrieve existing reflectance data to avoid duplicates
filesDownR <- drive_ls("WQP_SR_MatchUps_dswe_v2/") %>% 
  select(name)

```

#Open a python bash script to interact with Google Earth Engine using the package reticulate.

Reticulate uses the default python path for the local machine.  This python needs to be authorized with google earth engine and have the necessary packages installed. To change the Python called by reticulate, change the default located in your .Rprofile.  This is done here using the 'Sys.setenv()' command at the top of the chunk. For more information on Reticulate go to https://github.com/rstudio/reticulate* 


```{r reticulate_version}

library(reticulate)

reticulate_python <-'C:/Users/John/Anaconda3/envs/earthEngineGrabR/python.exe'
Sys.setenv(RETICULATE_PYTHON = reticulate_python)
use_condaenv("earthEngineGrabR", required=TRUE)
py_config()

```


```{python,eval=do_it}

## python, engine.path ="C:/Users/john/Anaconda2/envs/watersat/python.exe"
import time
import ee
import os
import feather
ee.Initialize()

#Source necessary functions.
execfile('2_rsdata/src/GEE_pull_functions_matchups.py')
#exec(open("D:/Dropbox/projects/TSS/code/GEE_pull_functions_matchups.py").read())    

#Load in Pekel water occurance Layer and Landsat Collections.
PekelMask = False
pekel = ee.Image('JRC/GSW1_0/GlobalSurfaceWater')
l8 = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')
l7 = ee.ImageCollection('LANDSAT/LE07/C01/T1_SR')
l5 = ee.ImageCollection('LANDSAT/LT05/C01/T1_SR')

#Identify collection for use in sourced functions.
collection = 'SR'

#Standardize band names between the various collections and aggregate 
#them into one image collection
bn8 = ['B2','B3', 'B4', 'B5', 'B6','B7', 'pixel_qa']
bn57 = ['B1', 'B2', 'B3', 'B4', 'B5','B7', 'pixel_qa']
bns = ['Blue', 'Green', 'Red', 'Nir', 'Swir1', 'Swir2', 'qa']
  
ls5 = l5.select(bn57, bns)
ls7 = l7.select(bn57, bns)
ls8 = l8.select(bn8, bns)
ls = ee.ImageCollection(ls5.merge(ls7).merge(ls8))

#Select the occurence layer in the pekel mask, which is just the 
#percentage of water occurence over a given pixel from 1985-2015.
#Set the percent occurance threshold and create a watermask from the result.
if PekelMask == True:
  threshold = 80
  water = pekel.select('occurrence').gt(threshold)
  water = water.updateMask(water)
  
#Set buffer distance of pixels to include in median and standard deviation #calculation.  Distance is in meters from supplied sample point.  
dist = 200

## Identify folder with in-situ data broken up into 5000 observation chunks by path/row
ULdir = 'D:/Dropbox/projects/TSS/output/split_wide/'

#Generate file lists for both files to be sent and files already processed in google earth engine
dlDir = 'D:/GoogleDrive/WQP_SR_MatchUps_dswe_v2/' 
filesDown = os.listdir(dlDir)  
#filesDown = r.filesDownR['name']
filesUp = os.listdir(ULdir) 

#Remove hidden formatting file in directory and any file names in filesUp that are already in files down.
filesUpFlt  = filter(lambda x: x  != '.DS_Store', filesUp)
filesDown = [i.replace(".csv", ".feather") for i in filesDown]
filesUpFlt  = filter(lambda x: x  != '.placeholder', filesUpFlt)
counter = 0

#### Wrap it all up in a for loop running through our list of files
for x in range(0,len(filesUpFlt)):
  #Read in our file as a feather data frame
  inv = feather.read_dataframe(ULdir + filesUpFlt[x])
  #turn our inventory into a feature collection by assigning 
  #lat longs and a site id.  Do this via list comprehension 
  #(similar to for loop but faster and plays nice with earth engine.)
  invOut = ee.FeatureCollection([ee.Feature(ee.Geometry.Point([inv['long'][i],\
  inv['lat'][i]]),{'SiteID':inv['SiteID'][i],\
  'date':inv['date'][i],'date_unity':inv['date_unity'][i]}) for i in range(0,len(inv))]) 
  
  #Pull out the path/row from the file name
  path = int(filesUpFlt[x].replace('.','_').split('_')[0])
  row = int(filesUpFlt[x].replace('.','_').split('_')[1])
  
  #Filter image collection to path/row  
  lsover = ee.ImageCollection(ls.filter(ee.Filter.eq('WRS_PATH',\
  path)).filter(ee.Filter.eq('WRS_ROW', row)))
    
  ## Map over sites within specific path/row and pull reflectance values
  data = ee.FeatureCollection(invOut.map(sitePull))
  
  #Extract path/row count Variable so names match up with file sent to GGE
  if filesUpFlt[x].replace('.','_').split('_')[2] == 'feather':
    count = ''
  else:
    count = '_'+str(int(filesUpFlt[x].replace('.','_').split('_')[2]))
  #Create queue of tasks to export to earth engine
  dataOut = ee.batch.Export.table.toDrive(collection = data, \
                                              description = str(path)\
                                               +'_'+str(row) + count,\
                                              folder = 'WQP_SR_MatchUps_dswe_v2',\
                                              fileFormat = 'csv')
  #Check how many existing tasks are running and take a break if it's >15
  maximum_no_of_tasks(15, 60)
  #Send next task.
  dataOut.start()
  counter = counter + 1
  print('done_'+ str(counter))
  
#Make sure all Earth engine tasks are completed prior to moving on.  
maximum_no_of_tasks(1,300)
print('done')

```

